2025-01-01 19:45:53 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: pw_scraper)
2025-01-01 19:45:53 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.13.0 (tags/v3.13.0:60403a5, Oct  7 2024, 09:38:07) [MSC v.1941 64 bit (AMD64)], pyOpenSSL 24.3.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.22631-SP0
2025-01-01 19:45:53 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-01 19:45:53 [py.warnings] WARNING: C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\request.py:120: ScrapyDeprecationWarning: 'REQUEST_FINGERPRINTER_IMPLEMENTATION' is a deprecated setting.
It will be removed in a future version of Scrapy.
  return cls(crawler)

2025-01-01 19:45:53 [scrapy.extensions.telnet] INFO: Telnet Password: 7787236366bfbd61
2025-01-01 19:45:53 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2025-01-01 19:45:53 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_ENABLED': True,
 'BOT_NAME': 'pw_scraper',
 'CONCURRENT_REQUESTS': 32,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_errors.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'pw_scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'RETRY_HTTP_CODES': [500],
 'RETRY_TIMES': 5,
 'SPIDER_MODULES': ['pw_scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-01 19:45:53 [scrapy-playwright] INFO: Started loop on separate thread: <ProactorEventLoop running=True closed=False debug=False>
2025-01-01 19:45:53 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'pw_scraper.middlewares.pw_scraperDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-01 19:45:53 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-01 19:45:53 [scrapy.middleware] INFO: Enabled item pipelines:
['pw_scraper.pipelines.pw_scraperPipeline']
2025-01-01 19:45:53 [scrapy.core.engine] INFO: Spider opened
2025-01-01 19:45:53 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-01 19:45:53 [pw_spider] INFO: Spider opened: pw_spider
2025-01-01 19:45:53 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-01 19:45:53 [scrapy-playwright] INFO: Starting download handler
2025-01-01 19:45:53 [scrapy-playwright] INFO: Starting download handler
2025-01-01 19:46:01 [scrapy-playwright] INFO: Launching browser chromium
2025-01-01 19:46:01 [scrapy-playwright] INFO: Browser chromium launched
2025-01-01 19:46:53 [scrapy.extensions.logstats] INFO: Crawled 7 pages (at 7 pages/min), scraped 42 items (at 42 items/min)
2025-01-01 19:58:52 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: pw_scraper)
2025-01-01 19:58:52 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.13.0 (tags/v3.13.0:60403a5, Oct  7 2024, 09:38:07) [MSC v.1941 64 bit (AMD64)], pyOpenSSL 24.3.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.22631-SP0
2025-01-01 19:58:52 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-01 19:58:52 [py.warnings] WARNING: C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\request.py:120: ScrapyDeprecationWarning: 'REQUEST_FINGERPRINTER_IMPLEMENTATION' is a deprecated setting.
It will be removed in a future version of Scrapy.
  return cls(crawler)

2025-01-01 19:58:52 [scrapy.extensions.telnet] INFO: Telnet Password: 473f147f9e9a073d
2025-01-01 19:58:52 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2025-01-01 19:58:52 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_ENABLED': True,
 'BOT_NAME': 'pw_scraper',
 'CONCURRENT_REQUESTS': 32,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_errors.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'pw_scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'RETRY_HTTP_CODES': [500],
 'RETRY_TIMES': 5,
 'SPIDER_MODULES': ['pw_scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-01 19:58:52 [scrapy-playwright] INFO: Started loop on separate thread: <ProactorEventLoop running=True closed=False debug=False>
2025-01-01 19:58:52 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'pw_scraper.middlewares.pw_scraperDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-01 19:58:52 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-01 19:58:52 [scrapy.middleware] INFO: Enabled item pipelines:
['pw_scraper.pipelines.pw_scraperPipeline']
2025-01-01 19:58:52 [scrapy.core.engine] INFO: Spider opened
2025-01-01 19:58:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-01 19:58:52 [pw_spider] INFO: Spider opened: pw_spider
2025-01-01 19:58:52 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-01 19:58:52 [scrapy-playwright] INFO: Starting download handler
2025-01-01 19:58:52 [scrapy-playwright] INFO: Starting download handler
2025-01-01 19:59:04 [scrapy-playwright] INFO: Launching browser chromium
2025-01-01 19:59:04 [scrapy-playwright] INFO: Browser chromium launched
2025-01-01 19:59:27 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-01 19:59:27 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1249,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 461903,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 35.013824,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 1, 18, 59, 27, 880314, tzinfo=datetime.timezone.utc),
 'item_scraped_count': 20,
 'items_per_minute': None,
 'log_count/INFO': 16,
 'log_count/WARNING': 1,
 'playwright/browser_count': 1,
 'playwright/context_count': 1,
 'playwright/context_count/max_concurrent': 1,
 'playwright/context_count/persistent/False': 1,
 'playwright/context_count/remote/False': 1,
 'playwright/page_count': 2,
 'playwright/page_count/max_concurrent': 1,
 'playwright/request_count': 173,
 'playwright/request_count/aborted': 84,
 'playwright/request_count/method/GET': 168,
 'playwright/request_count/method/POST': 5,
 'playwright/request_count/navigation': 3,
 'playwright/request_count/resource_type/document': 3,
 'playwright/request_count/resource_type/fetch': 2,
 'playwright/request_count/resource_type/image': 27,
 'playwright/request_count/resource_type/script': 81,
 'playwright/request_count/resource_type/stylesheet': 57,
 'playwright/request_count/resource_type/xhr': 3,
 'playwright/response_count': 88,
 'playwright/response_count/method/GET': 84,
 'playwright/response_count/method/POST': 4,
 'playwright/response_count/resource_type/document': 3,
 'playwright/response_count/resource_type/fetch': 1,
 'playwright/response_count/resource_type/script': 81,
 'playwright/response_count/resource_type/xhr': 3,
 'request_depth_max': 2,
 'response_received_count': 3,
 'responses_per_minute': None,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 1, 18, 58, 52, 866490, tzinfo=datetime.timezone.utc)}
2025-01-01 19:59:27 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-01 19:59:27 [scrapy-playwright] INFO: Closing download handler
2025-01-01 19:59:28 [scrapy-playwright] INFO: Closing download handler
2025-01-01 19:59:28 [scrapy-playwright] INFO: Closing browser
2025-01-01 20:07:13 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: pw_scraper)
2025-01-01 20:07:13 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.13.0 (tags/v3.13.0:60403a5, Oct  7 2024, 09:38:07) [MSC v.1941 64 bit (AMD64)], pyOpenSSL 24.3.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.22631-SP0
2025-01-01 20:07:13 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-01 20:07:13 [py.warnings] WARNING: C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\request.py:120: ScrapyDeprecationWarning: 'REQUEST_FINGERPRINTER_IMPLEMENTATION' is a deprecated setting.
It will be removed in a future version of Scrapy.
  return cls(crawler)

2025-01-01 20:07:13 [scrapy.extensions.telnet] INFO: Telnet Password: 0a48ee6b7f9f07c8
2025-01-01 20:07:13 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2025-01-01 20:07:13 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_ENABLED': True,
 'BOT_NAME': 'pw_scraper',
 'CONCURRENT_REQUESTS': 32,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_errors.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'pw_scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'RETRY_HTTP_CODES': [500],
 'RETRY_TIMES': 5,
 'SPIDER_MODULES': ['pw_scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-01 20:07:13 [scrapy-playwright] INFO: Started loop on separate thread: <ProactorEventLoop running=True closed=False debug=False>
2025-01-01 20:07:13 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'pw_scraper.middlewares.pw_scraperDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-01 20:07:13 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-01 20:07:13 [twisted] CRITICAL: Unhandled error in Deferred:
2025-01-01 20:07:13 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\crawler.py", line 152, in crawl
    self.engine = self._create_engine()
                  ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\crawler.py", line 166, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\core\engine.py", line 102, in __init__
    self.scraper: Scraper = Scraper(crawler)
                            ~~~~~~~^^^^^^^^^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\core\scraper.py", line 101, in __init__
    self.itemproc: ItemPipelineManager = itemproc_cls.from_crawler(crawler)
                                         ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\middleware.py", line 77, in from_crawler
    return cls._from_settings(crawler.settings, crawler)
           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\middleware.py", line 86, in _from_settings
    mwcls = load_object(clspath)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\misc.py", line 71, in load_object
    mod = import_module(module)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\importlib\__init__.py", line 88, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 1018, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1156, in get_code
  File "<frozen importlib._bootstrap_external>", line 1086, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 43
    json.dump(data, file, indent=4)
    ^^^^
IndentationError: expected an indented block after 'with' statement on line 42
2025-01-01 20:07:34 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: pw_scraper)
2025-01-01 20:07:34 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.13.0 (tags/v3.13.0:60403a5, Oct  7 2024, 09:38:07) [MSC v.1941 64 bit (AMD64)], pyOpenSSL 24.3.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.22631-SP0
2025-01-01 20:07:34 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-01 20:07:34 [py.warnings] WARNING: C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\request.py:120: ScrapyDeprecationWarning: 'REQUEST_FINGERPRINTER_IMPLEMENTATION' is a deprecated setting.
It will be removed in a future version of Scrapy.
  return cls(crawler)

2025-01-01 20:07:34 [scrapy.extensions.telnet] INFO: Telnet Password: adb14884e27fee4f
2025-01-01 20:07:34 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2025-01-01 20:07:34 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_ENABLED': True,
 'BOT_NAME': 'pw_scraper',
 'CONCURRENT_REQUESTS': 32,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_errors.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'pw_scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'RETRY_HTTP_CODES': [500],
 'RETRY_TIMES': 5,
 'SPIDER_MODULES': ['pw_scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-01 20:07:34 [scrapy-playwright] INFO: Started loop on separate thread: <ProactorEventLoop running=True closed=False debug=False>
2025-01-01 20:07:35 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'pw_scraper.middlewares.pw_scraperDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-01 20:07:35 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-01 20:07:35 [scrapy.middleware] INFO: Enabled item pipelines:
['pw_scraper.pipelines.pw_scraperPipeline']
2025-01-01 20:07:35 [scrapy.core.engine] INFO: Spider opened
2025-01-01 20:07:35 [scrapy.core.engine] INFO: Closing spider (shutdown)
2025-01-01 20:07:35 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method CoreStats.spider_closed of <scrapy.extensions.corestats.CoreStats object at 0x000001F292ACE270>>
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\crawler.py", line 154, in crawl
    yield self.engine.open_spider(self.spider, start_requests)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
        cast(Failure, result).throwExceptionIntoGenerator, gen
    )
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\core\engine.py", line 395, in open_spider
    yield self.scraper.open_spider(spider)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
        cast(Failure, result).throwExceptionIntoGenerator, gen
    )
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\core\scraper.py", line 112, in open_spider
    yield self.itemproc.open_spider(spider)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 17, in open_spider
    self.logger.info("Initialized organisation.json and links.json")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 400, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\extensions\corestats.py", line 41, in spider_closed
    assert self.start_time is not None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError
2025-01-01 20:07:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'items_per_minute': None,
 'log_count/ERROR': 1,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'responses_per_minute': None}
2025-01-01 20:07:35 [scrapy.core.engine] INFO: Spider closed (shutdown)
2025-01-01 20:07:35 [twisted] CRITICAL: Unhandled error in Deferred:
2025-01-01 20:07:35 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\crawler.py", line 154, in crawl
    yield self.engine.open_spider(self.spider, start_requests)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
        cast(Failure, result).throwExceptionIntoGenerator, gen
    )
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\core\engine.py", line 395, in open_spider
    yield self.scraper.open_spider(spider)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
        cast(Failure, result).throwExceptionIntoGenerator, gen
    )
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\core\scraper.py", line 112, in open_spider
    yield self.itemproc.open_spider(spider)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 17, in open_spider
    self.logger.info("Initialized organisation.json and links.json")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:08:47 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: pw_scraper)
2025-01-01 20:08:47 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.13.0 (tags/v3.13.0:60403a5, Oct  7 2024, 09:38:07) [MSC v.1941 64 bit (AMD64)], pyOpenSSL 24.3.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.22631-SP0
2025-01-01 20:08:47 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-01 20:08:47 [py.warnings] WARNING: C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\request.py:120: ScrapyDeprecationWarning: 'REQUEST_FINGERPRINTER_IMPLEMENTATION' is a deprecated setting.
It will be removed in a future version of Scrapy.
  return cls(crawler)

2025-01-01 20:08:47 [scrapy.extensions.telnet] INFO: Telnet Password: e62ea70665968bbc
2025-01-01 20:08:47 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2025-01-01 20:08:47 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_ENABLED': True,
 'BOT_NAME': 'pw_scraper',
 'CONCURRENT_REQUESTS': 32,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_errors.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'pw_scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'RETRY_HTTP_CODES': [500],
 'RETRY_TIMES': 5,
 'SPIDER_MODULES': ['pw_scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-01 20:08:47 [scrapy-playwright] INFO: Started loop on separate thread: <ProactorEventLoop running=True closed=False debug=False>
2025-01-01 20:08:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'pw_scraper.middlewares.pw_scraperDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-01 20:08:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-01 20:08:48 [scrapy.middleware] INFO: Enabled item pipelines:
['pw_scraper.pipelines.pw_scraperPipeline']
2025-01-01 20:08:48 [scrapy.core.engine] INFO: Spider opened
2025-01-01 20:08:48 [pw_spider] INFO: Initialized organisation.json and links.json
2025-01-01 20:08:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-01 20:08:48 [pw_spider] INFO: Spider opened: pw_spider
2025-01-01 20:08:48 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-01 20:08:48 [scrapy-playwright] INFO: Starting download handler
2025-01-01 20:08:48 [scrapy-playwright] INFO: Starting download handler
2025-01-01 20:08:59 [scrapy-playwright] INFO: Launching browser chromium
2025-01-01 20:08:59 [scrapy-playwright] INFO: Browser chromium launched
2025-01-01 20:09:23 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WEiTI-2b1d08b0-283d-4e9b-a127-188c08edb157?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BMarek%2BMisiurewicz%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 45, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")  # Debugging
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:09:23 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT28cd89ddb75c444b8f55cec74bce66b3?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BAlina%2BPo%25C5%2582ocka%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 45, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")  # Debugging
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:09:23 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT3e3691c7d8704fd0ba0b8173a4259e75?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BEl%25C5%25BCbieta%2BMre%25C5%2584ca%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 45, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")  # Debugging
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:09:23 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT66f74ffcc2714395b41eeca155385a0d?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BIzabela%2BKopto%25C5%2584-Ryniec%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 45, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")  # Debugging
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:09:23 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUTc0424f246de84d47b7cf548ea3043fb5?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BAdam%2BPieni%25C4%2585%25C5%25BCek%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 45, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")  # Debugging
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:09:23 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUTfadf8bf9e6734c2d965a4c86474504dc?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BMicha%25C5%2582%2B%25C5%2581a%25C5%25BAniewski%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 45, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")  # Debugging
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:09:23 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT4e08f253ffef434482beea1cd55a7291?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BJan%2BDubi%25C5%2584ski%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 45, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")  # Debugging
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:09:23 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT93268d1412254e9b9815420c0212afff?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BEwa%2BKije%25C5%2584ska-Gawro%25C5%2584ska%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 45, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")  # Debugging
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:09:23 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT30e49070c8cb40e68c65102054e77507?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BWioleta%2BRz%25C4%2599sa%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 45, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")  # Debugging
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:09:23 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT4fcb28c63bb549ed9a2648781878d4fc?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BMonika%2BBil%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 45, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")  # Debugging
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:09:23 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT9fcba297d6564beab95c625ad5c72923?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BMaciej%2BTrzaskowski%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 45, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")  # Debugging
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:09:23 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUTd80cebd39dad4f7293e728b044cb9d72?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BKamil%2B%25C5%25BBukowski%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 45, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")  # Debugging
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:09:23 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUTa92ff65475064f33989fdb56b969ab4f?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BDominika%2BBury%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 45, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")  # Debugging
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:09:23 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT445ecb8ee2854021a815ccaf95b28294?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BPaulina%2BAnna%2BTrzaskowska%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 45, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")  # Debugging
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:09:23 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT63387fc588874edd9e9582498b453de2?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BKatarzyna%2BTokarska%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 45, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")  # Debugging
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:09:23 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT937061d1692c4fda81e2ba20998bf56b?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BMarcin%2BMy%25C5%259Bliwiec%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 45, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")  # Debugging
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:09:23 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUTb64563bf72e44c1da6d9f5eba8286d19?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BKrzysztof%2BStasiak%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 45, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")  # Debugging
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:09:23 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT817d3b704a4e4a9aa3d856fb8a51d539?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BBartosz%2BMichalak%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 45, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")  # Debugging
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:09:23 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUTc14b3609e44f493d9327fd99f1c3e1a5?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BMagdalena%2BFlont%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 45, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")  # Debugging
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:09:23 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUTd3dec995be39439f93ef94e66cce12d5?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BAliaksandr%2BMartsinchyk%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 45, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")  # Debugging
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:09:25 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-01 20:09:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1249,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 461910,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 36.589958,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 1, 19, 9, 25, 75324, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/ERROR': 20,
 'log_count/INFO': 17,
 'log_count/WARNING': 1,
 'playwright/browser_count': 1,
 'playwright/context_count': 1,
 'playwright/context_count/max_concurrent': 1,
 'playwright/context_count/persistent/False': 1,
 'playwright/context_count/remote/False': 1,
 'playwright/page_count': 2,
 'playwright/page_count/max_concurrent': 1,
 'playwright/request_count': 174,
 'playwright/request_count/aborted': 84,
 'playwright/request_count/method/GET': 168,
 'playwright/request_count/method/POST': 6,
 'playwright/request_count/navigation': 3,
 'playwright/request_count/resource_type/document': 3,
 'playwright/request_count/resource_type/fetch': 3,
 'playwright/request_count/resource_type/image': 27,
 'playwright/request_count/resource_type/script': 81,
 'playwright/request_count/resource_type/stylesheet': 57,
 'playwright/request_count/resource_type/xhr': 3,
 'playwright/response_count': 89,
 'playwright/response_count/method/GET': 84,
 'playwright/response_count/method/POST': 5,
 'playwright/response_count/resource_type/document': 3,
 'playwright/response_count/resource_type/fetch': 2,
 'playwright/response_count/resource_type/script': 81,
 'playwright/response_count/resource_type/xhr': 3,
 'request_depth_max': 2,
 'response_received_count': 3,
 'responses_per_minute': None,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 1, 19, 8, 48, 485366, tzinfo=datetime.timezone.utc)}
2025-01-01 20:09:25 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-01 20:09:25 [scrapy-playwright] INFO: Closing download handler
2025-01-01 20:09:26 [scrapy-playwright] INFO: Closing download handler
2025-01-01 20:09:26 [scrapy-playwright] INFO: Closing browser
2025-01-01 20:15:29 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: pw_scraper)
2025-01-01 20:15:29 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.13.0 (tags/v3.13.0:60403a5, Oct  7 2024, 09:38:07) [MSC v.1941 64 bit (AMD64)], pyOpenSSL 24.3.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.22631-SP0
2025-01-01 20:15:29 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-01 20:15:29 [py.warnings] WARNING: C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\request.py:120: ScrapyDeprecationWarning: 'REQUEST_FINGERPRINTER_IMPLEMENTATION' is a deprecated setting.
It will be removed in a future version of Scrapy.
  return cls(crawler)

2025-01-01 20:15:29 [scrapy.extensions.telnet] INFO: Telnet Password: 8f200a5e839849e4
2025-01-01 20:15:29 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2025-01-01 20:15:29 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_ENABLED': True,
 'BOT_NAME': 'pw_scraper',
 'CONCURRENT_REQUESTS': 32,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_errors.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'pw_scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'RETRY_HTTP_CODES': [500],
 'RETRY_TIMES': 5,
 'SPIDER_MODULES': ['pw_scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-01 20:15:29 [scrapy-playwright] INFO: Started loop on separate thread: <ProactorEventLoop running=True closed=False debug=False>
2025-01-01 20:15:29 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'pw_scraper.middlewares.pw_scraperDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-01 20:15:29 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-01 20:15:29 [scrapy.middleware] INFO: Enabled item pipelines:
['pw_scraper.pipelines.pw_scraperPipeline']
2025-01-01 20:15:29 [scrapy.core.engine] INFO: Spider opened
2025-01-01 20:15:29 [scrapy.core.engine] INFO: Closing spider (shutdown)
2025-01-01 20:15:29 [scrapy.core.engine] ERROR: Scraper close failure
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\crawler.py", line 154, in crawl
    yield self.engine.open_spider(self.spider, start_requests)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
        cast(Failure, result).throwExceptionIntoGenerator, gen
    )
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\core\engine.py", line 395, in open_spider
    yield self.scraper.open_spider(spider)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
        cast(Failure, result).throwExceptionIntoGenerator, gen
    )
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\core\scraper.py", line 112, in open_spider
    yield self.itemproc.open_spider(spider)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 16, in open_spider
    self.logger.info("Initialized organisation.json and links.json")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 19, in close_spider
    self.logger.info("Spider finished")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:15:29 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method CoreStats.spider_closed of <scrapy.extensions.corestats.CoreStats object at 0x000002BC0484A3C0>>
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\crawler.py", line 154, in crawl
    yield self.engine.open_spider(self.spider, start_requests)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
        cast(Failure, result).throwExceptionIntoGenerator, gen
    )
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\core\engine.py", line 395, in open_spider
    yield self.scraper.open_spider(spider)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
        cast(Failure, result).throwExceptionIntoGenerator, gen
    )
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\core\scraper.py", line 112, in open_spider
    yield self.itemproc.open_spider(spider)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 16, in open_spider
    self.logger.info("Initialized organisation.json and links.json")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 400, in maybeDeferred_coro
    result = f(*args, **kw)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\extensions\corestats.py", line 41, in spider_closed
    assert self.start_time is not None
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
AssertionError
2025-01-01 20:15:29 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'items_per_minute': None,
 'log_count/ERROR': 2,
 'log_count/INFO': 9,
 'log_count/WARNING': 1,
 'responses_per_minute': None}
2025-01-01 20:15:29 [scrapy.core.engine] INFO: Spider closed (shutdown)
2025-01-01 20:15:29 [twisted] CRITICAL: Unhandled error in Deferred:
2025-01-01 20:15:29 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 2017, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\crawler.py", line 154, in crawl
    yield self.engine.open_spider(self.spider, start_requests)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
        cast(Failure, result).throwExceptionIntoGenerator, gen
    )
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\core\engine.py", line 395, in open_spider
    yield self.scraper.open_spider(spider)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 2013, in _inlineCallbacks
    result = context.run(
        cast(Failure, result).throwExceptionIntoGenerator, gen
    )
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\python\failure.py", line 467, in throwExceptionIntoGenerator
    return g.throw(self.value.with_traceback(self.tb))
           ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\core\scraper.py", line 112, in open_spider
    yield self.itemproc.open_spider(spider)
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 16, in open_spider
    self.logger.info("Initialized organisation.json and links.json")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:04 [scrapy.utils.log] INFO: Scrapy 2.12.0 started (bot: pw_scraper)
2025-01-01 20:16:04 [scrapy.utils.log] INFO: Versions: lxml 5.3.0.0, libxml2 2.11.7, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.11.0, Python 3.13.0 (tags/v3.13.0:60403a5, Oct  7 2024, 09:38:07) [MSC v.1941 64 bit (AMD64)], pyOpenSSL 24.3.0 (OpenSSL 3.4.0 22 Oct 2024), cryptography 44.0.0, Platform Windows-11-10.0.22631-SP0
2025-01-01 20:16:04 [scrapy.addons] INFO: Enabled addons:
[]
2025-01-01 20:16:04 [py.warnings] WARNING: C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\request.py:120: ScrapyDeprecationWarning: 'REQUEST_FINGERPRINTER_IMPLEMENTATION' is a deprecated setting.
It will be removed in a future version of Scrapy.
  return cls(crawler)

2025-01-01 20:16:04 [scrapy.extensions.telnet] INFO: Telnet Password: 33860b8f53c438dd
2025-01-01 20:16:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle']
2025-01-01 20:16:04 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_ENABLED': True,
 'BOT_NAME': 'pw_scraper',
 'CONCURRENT_REQUESTS': 32,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'LOG_FILE': 'scrapy_errors.log',
 'LOG_LEVEL': 'INFO',
 'NEWSPIDER_MODULE': 'pw_scraper.spiders',
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'RETRY_HTTP_CODES': [500],
 'RETRY_TIMES': 5,
 'SPIDER_MODULES': ['pw_scraper.spiders'],
 'TWISTED_REACTOR': 'twisted.internet.asyncioreactor.AsyncioSelectorReactor'}
2025-01-01 20:16:04 [scrapy-playwright] INFO: Started loop on separate thread: <ProactorEventLoop running=True closed=False debug=False>
2025-01-01 20:16:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'pw_scraper.middlewares.pw_scraperDownloaderMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2025-01-01 20:16:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-01-01 20:16:05 [scrapy.middleware] INFO: Enabled item pipelines:
['pw_scraper.pipelines.pw_scraperPipeline']
2025-01-01 20:16:05 [scrapy.core.engine] INFO: Spider opened
2025-01-01 20:16:05 [pw_spider] INFO: Initialized organisation.json and links.json
2025-01-01 20:16:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2025-01-01 20:16:05 [pw_spider] INFO: Spider opened: pw_spider
2025-01-01 20:16:05 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2025-01-01 20:16:05 [scrapy-playwright] INFO: Starting download handler
2025-01-01 20:16:05 [scrapy-playwright] INFO: Starting download handler
2025-01-01 20:16:15 [scrapy-playwright] INFO: Launching browser chromium
2025-01-01 20:16:15 [scrapy-playwright] INFO: Browser chromium launched
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'College of Economics and Social Sciences',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'College of Economics and Social Sciences',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Faculty of Administration and Social Sciences',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Faculty of Administration and Social Sciences',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Faculty of Architecture',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Faculty of Architecture',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Faculty of Automotive and Construction Machinery Engineering',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Faculty of Automotive and Construction Machinery Engineering',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Faculty of Building Services, Hydro and Environmental '
              'Engineering',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Faculty of Building Services, Hydro and Environmental '
              'Engineering',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Faculty of Chemical and Process Engineering',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Faculty of Chemical and Process Engineering',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Faculty of Chemistry',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Faculty of Chemistry',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Faculty of Civil Engineering',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Faculty of Civil Engineering',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Faculty of Civil Engineering, Mechanics and Petrochemistry',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Faculty of Civil Engineering, Mechanics and Petrochemistry',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Faculty of Electrical Engineering',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Faculty of Electrical Engineering',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Faculty of Electronics and Information Technology',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Faculty of Electronics and Information Technology',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Faculty of Geodesy and Cartography',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Faculty of Geodesy and Cartography',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Faculty of Management',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Faculty of Management',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Faculty of Materials Science and Engineering',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Faculty of Materials Science and Engineering',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Faculty of Mathematics and Information Sciences',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Faculty of Mathematics and Information Sciences',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Faculty of Mechanical and Industrial Engineering',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Faculty of Mechanical and Industrial Engineering',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Faculty of Mechatronics',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Faculty of Mechatronics',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Faculty of Physics',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Faculty of Physics',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Faculty of Power and Aeronautical Engineering',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Faculty of Power and Aeronautical Engineering',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Faculty of Transport',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Faculty of Transport',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Business School',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Business School',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Centre for Development Projects',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Centre for Development Projects',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Centre for International Cooperation',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Centre for International Cooperation',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Distance Learning Center',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Distance Learning Center',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Doctoral School',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Doctoral School',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Innovations Center',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Innovations Center',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Main Library of Warsaw University of Technology',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Main Library of Warsaw University of Technology',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Office for Communications and Promotion of WUT',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Office for Communications and Promotion of WUT',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Project Office  EIRU',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Project Office  EIRU',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Project Support Centre',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Project Support Centre',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Scientific Councils',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Scientific Councils',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Strategic Analysis Department',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Strategic Analysis Department',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'The Centre for Advanced Materials and Technologies',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'The Centre for Advanced Materials and Technologies',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'The Centre for Innovation and Technology Transfer Management',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'The Centre for Innovation and Technology Transfer Management',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'The Foreign Language Centre',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'The Foreign Language Centre',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'The Physical Education Centre',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'The Physical Education Centre',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'The University Research Center of Aviation and Cosmonautics',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'The University Research Center of Aviation and Cosmonautics',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'University Defense and Security Research Center',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'University Defense and Security Research Center',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'University Research Center "Functional Materials"',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'University Research Center "Functional Materials"',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'WUT Central Administration',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'WUT Central Administration',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'WUT Information Technology Centre',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'WUT Information Technology Centre',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:25 [pw_spider] INFO: Yielding organization: {'cathedras': [],
 'institute': 'Third Age University of WTU',
 'university': 'Warsaw University of Technology'}
2025-01-01 20:16:25 [scrapy.core.scraper] ERROR: Error processing {'cathedras': [],
 'institute': 'Third Age University of WTU',
 'university': 'Warsaw University of Technology'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:35 [pw_spider] INFO: Found scientist link: https://repo.pw.edu.pl/info/author/WEiTI-2b1d08b0-283d-4e9b-a127-188c08edb157?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BMarek%2BMisiurewicz%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse
2025-01-01 20:16:35 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WEiTI-2b1d08b0-283d-4e9b-a127-188c08edb157?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BMarek%2BMisiurewicz%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:35 [pw_spider] INFO: Found scientist link: https://repo.pw.edu.pl/info/author/WUT28cd89ddb75c444b8f55cec74bce66b3?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BAlina%2BPo%25C5%2582ocka%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse
2025-01-01 20:16:35 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT28cd89ddb75c444b8f55cec74bce66b3?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BAlina%2BPo%25C5%2582ocka%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:35 [pw_spider] INFO: Found scientist link: https://repo.pw.edu.pl/info/author/WUT3e3691c7d8704fd0ba0b8173a4259e75?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BEl%25C5%25BCbieta%2BMre%25C5%2584ca%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse
2025-01-01 20:16:35 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT3e3691c7d8704fd0ba0b8173a4259e75?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BEl%25C5%25BCbieta%2BMre%25C5%2584ca%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:35 [pw_spider] INFO: Found scientist link: https://repo.pw.edu.pl/info/author/WUT66f74ffcc2714395b41eeca155385a0d?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BIzabela%2BKopto%25C5%2584-Ryniec%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse
2025-01-01 20:16:35 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT66f74ffcc2714395b41eeca155385a0d?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BIzabela%2BKopto%25C5%2584-Ryniec%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:35 [pw_spider] INFO: Found scientist link: https://repo.pw.edu.pl/info/author/WUTc0424f246de84d47b7cf548ea3043fb5?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BAdam%2BPieni%25C4%2585%25C5%25BCek%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse
2025-01-01 20:16:35 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUTc0424f246de84d47b7cf548ea3043fb5?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BAdam%2BPieni%25C4%2585%25C5%25BCek%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:35 [pw_spider] INFO: Found scientist link: https://repo.pw.edu.pl/info/author/WUTfadf8bf9e6734c2d965a4c86474504dc?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BMicha%25C5%2582%2B%25C5%2581a%25C5%25BAniewski%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse
2025-01-01 20:16:35 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUTfadf8bf9e6734c2d965a4c86474504dc?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BMicha%25C5%2582%2B%25C5%2581a%25C5%25BAniewski%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:35 [pw_spider] INFO: Found scientist link: https://repo.pw.edu.pl/info/author/WUT4e08f253ffef434482beea1cd55a7291?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BJan%2BDubi%25C5%2584ski%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse
2025-01-01 20:16:35 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT4e08f253ffef434482beea1cd55a7291?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BJan%2BDubi%25C5%2584ski%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:35 [pw_spider] INFO: Found scientist link: https://repo.pw.edu.pl/info/author/WUT93268d1412254e9b9815420c0212afff?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BEwa%2BKije%25C5%2584ska-Gawro%25C5%2584ska%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse
2025-01-01 20:16:35 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT93268d1412254e9b9815420c0212afff?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BEwa%2BKije%25C5%2584ska-Gawro%25C5%2584ska%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:35 [pw_spider] INFO: Found scientist link: https://repo.pw.edu.pl/info/author/WUT30e49070c8cb40e68c65102054e77507?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BWioleta%2BRz%25C4%2599sa%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse
2025-01-01 20:16:35 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT30e49070c8cb40e68c65102054e77507?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BWioleta%2BRz%25C4%2599sa%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:35 [pw_spider] INFO: Found scientist link: https://repo.pw.edu.pl/info/author/WUT4fcb28c63bb549ed9a2648781878d4fc?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BMonika%2BBil%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse
2025-01-01 20:16:35 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT4fcb28c63bb549ed9a2648781878d4fc?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BMonika%2BBil%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:35 [pw_spider] INFO: Found scientist link: https://repo.pw.edu.pl/info/author/WUT9fcba297d6564beab95c625ad5c72923?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BMaciej%2BTrzaskowski%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse
2025-01-01 20:16:35 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT9fcba297d6564beab95c625ad5c72923?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BMaciej%2BTrzaskowski%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:35 [pw_spider] INFO: Found scientist link: https://repo.pw.edu.pl/info/author/WUTd80cebd39dad4f7293e728b044cb9d72?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BKamil%2B%25C5%25BBukowski%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse
2025-01-01 20:16:35 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUTd80cebd39dad4f7293e728b044cb9d72?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BKamil%2B%25C5%25BBukowski%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:35 [pw_spider] INFO: Found scientist link: https://repo.pw.edu.pl/info/author/WUTa92ff65475064f33989fdb56b969ab4f?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BDominika%2BBury%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse
2025-01-01 20:16:35 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUTa92ff65475064f33989fdb56b969ab4f?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BDominika%2BBury%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:35 [pw_spider] INFO: Found scientist link: https://repo.pw.edu.pl/info/author/WUT445ecb8ee2854021a815ccaf95b28294?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BPaulina%2BAnna%2BTrzaskowska%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse
2025-01-01 20:16:35 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT445ecb8ee2854021a815ccaf95b28294?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BPaulina%2BAnna%2BTrzaskowska%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:35 [pw_spider] INFO: Found scientist link: https://repo.pw.edu.pl/info/author/WUT63387fc588874edd9e9582498b453de2?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BKatarzyna%2BTokarska%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse
2025-01-01 20:16:35 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT63387fc588874edd9e9582498b453de2?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BKatarzyna%2BTokarska%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:35 [pw_spider] INFO: Found scientist link: https://repo.pw.edu.pl/info/author/WUT937061d1692c4fda81e2ba20998bf56b?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BMarcin%2BMy%25C5%259Bliwiec%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse
2025-01-01 20:16:35 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT937061d1692c4fda81e2ba20998bf56b?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BMarcin%2BMy%25C5%259Bliwiec%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:35 [pw_spider] INFO: Found scientist link: https://repo.pw.edu.pl/info/author/WUTb64563bf72e44c1da6d9f5eba8286d19?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BKrzysztof%2BStasiak%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse
2025-01-01 20:16:35 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUTb64563bf72e44c1da6d9f5eba8286d19?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BKrzysztof%2BStasiak%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:35 [pw_spider] INFO: Found scientist link: https://repo.pw.edu.pl/info/author/WUT817d3b704a4e4a9aa3d856fb8a51d539?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BBartosz%2BMichalak%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse
2025-01-01 20:16:35 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUT817d3b704a4e4a9aa3d856fb8a51d539?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BBartosz%2BMichalak%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:35 [pw_spider] INFO: Found scientist link: https://repo.pw.edu.pl/info/author/WUTc14b3609e44f493d9327fd99f1c3e1a5?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BMagdalena%2BFlont%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse
2025-01-01 20:16:35 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUTc14b3609e44f493d9327fd99f1c3e1a5?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BMagdalena%2BFlont%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:35 [pw_spider] INFO: Found scientist link: https://repo.pw.edu.pl/info/author/WUTd3dec995be39439f93ef94e66cce12d5?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BAliaksandr%2BMartsinchyk%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse
2025-01-01 20:16:35 [scrapy.core.scraper] ERROR: Error processing {'profile_url': 'https://repo.pw.edu.pl/info/author/WUTd3dec995be39439f93ef94e66cce12d5?r=author&tab=&title=Person%2Bprofile%2B%25E2%2580%2593%2BAliaksandr%2BMartsinchyk%2B%25E2%2580%2593%2BWarsaw%2BUniversity%2Bof%2BTechnology&lang=en&qp=openAccess%3Dfalse'}
Traceback (most recent call last):
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\twisted\internet\defer.py", line 1088, in _runCallbacks
    current.result = callback(  # type: ignore[misc]
                     ~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^
        current.result, *args, **kwargs
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\julia\AppData\Local\Programs\Python\Python313\Lib\site-packages\scrapy\utils\defer.py", line 390, in f
    return deferred_from_coro(coro_f(*coro_args, **coro_kwargs))
                              ~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\julia\OneDrive\Desktop\scraper\pw_scraper\pw_scraper\pipelines.py", line 39, in process_item
    self.logger.info(f"Saved item to {file_path}: {item}")
    ^^^^^^^^^^^
AttributeError: 'pw_scraperPipeline' object has no attribute 'logger'
2025-01-01 20:16:35 [scrapy.core.engine] INFO: Closing spider (finished)
2025-01-01 20:16:35 [pw_spider] INFO: Spider finished
2025-01-01 20:16:35 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1249,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 518954,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'elapsed_time_seconds': 30.741093,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2025, 1, 1, 19, 16, 35, 905506, tzinfo=datetime.timezone.utc),
 'items_per_minute': None,
 'log_count/ERROR': 62,
 'log_count/INFO': 80,
 'log_count/WARNING': 1,
 'playwright/browser_count': 1,
 'playwright/context_count': 1,
 'playwright/context_count/max_concurrent': 1,
 'playwright/context_count/persistent/False': 1,
 'playwright/context_count/remote/False': 1,
 'playwright/page_count': 2,
 'playwright/page_count/max_concurrent': 1,
 'playwright/request_count': 174,
 'playwright/request_count/aborted': 84,
 'playwright/request_count/method/GET': 168,
 'playwright/request_count/method/POST': 6,
 'playwright/request_count/navigation': 3,
 'playwright/request_count/resource_type/document': 3,
 'playwright/request_count/resource_type/fetch': 2,
 'playwright/request_count/resource_type/image': 27,
 'playwright/request_count/resource_type/script': 81,
 'playwright/request_count/resource_type/stylesheet': 57,
 'playwright/request_count/resource_type/xhr': 4,
 'playwright/response_count': 89,
 'playwright/response_count/method/GET': 84,
 'playwright/response_count/method/POST': 5,
 'playwright/response_count/resource_type/document': 3,
 'playwright/response_count/resource_type/fetch': 1,
 'playwright/response_count/resource_type/script': 81,
 'playwright/response_count/resource_type/xhr': 4,
 'request_depth_max': 2,
 'response_received_count': 3,
 'responses_per_minute': None,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2025, 1, 1, 19, 16, 5, 164413, tzinfo=datetime.timezone.utc)}
2025-01-01 20:16:35 [scrapy.core.engine] INFO: Spider closed (finished)
2025-01-01 20:16:35 [scrapy-playwright] INFO: Closing download handler
2025-01-01 20:16:36 [scrapy-playwright] INFO: Closing download handler
2025-01-01 20:16:36 [scrapy-playwright] INFO: Closing browser
